{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Hard Skill Detection </h2>\n",
    "\n",
    "Problem Statement:\n",
    "\n",
    "- Develop a code that can clean a dataset containing technical jargon and extract Technical (Hard) skills\n",
    "- Technical skills are defined as demonstrable and quantifiable skills. They can be tested to prove their capacity in each hard skill an individual possesses\n",
    "\n",
    "Sample of 900 random examples of technical skills will be provided\n",
    "\n",
    "Possible approaches:\n",
    "\n",
    "- Identify acronyms\n",
    "- Identify words that are not in dictionary\n",
    "- Create reference using Example list\n",
    "- Consider frequencies of words in the English language to identify unusual words/common words\n",
    "- Treat numeric values\n",
    "- Treat empty values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from wordfreq import zipf_frequency\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data including raw data, example list of hard skills, and words in English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Raw_Skills_Dataset.csv\")\n",
    "hardskills = pd.read_csv(\"Example_Technical_Skills.csv\")\n",
    "words_d = pd.read_csv(\"words.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_d = words_d.dropna()\n",
    "data = data.dropna()\n",
    "hardskills = hardskills.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create list with all words in English dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlist = list(words_d.iloc[:,0].astype('string'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create list of lists containing words split by characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for sub in stringlist:\n",
    "    res.append(list(sub))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create dictionary with all letters as keys and all words starting with the corresponding letter under that letter's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddict = {}\n",
    "\n",
    "for t in range(0,len(stringlist)):\n",
    "    if list(stringlist[t])[0] not in list(worddict.keys()):\n",
    "        worddict[list(stringlist[t])[0]] = list(stringlist[t])\n",
    "    else:\n",
    "        worddict[list(stringlist[t])[0]].append(stringlist[t])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create list containing data points of hard skills sample data, organized in lists containing individual words, with no special characters or numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist = pd.DataFrame(data = np.zeros(len(hardskills)), columns = ['Word Lists'])\n",
    "wlist = []\n",
    "for x in range(0,len(hardskills)):\n",
    "    \n",
    "    wlist.append(re.sub(r\"[^a-zA-Z]\",\" \", hardskills.iloc[x,0]).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create dictionary containing all words that appear in hard skills sample list, ensuring that words like \"the\", \"a\", etc are not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "\n",
    "for x in wlist:\n",
    "    for y in x:\n",
    "        if zipf_frequency(y, 'en',wordlist='small') > 6: #value of 6 for frequency ensured that non-key words would not be included\n",
    "            continue\n",
    "        else:\n",
    "            if y in list(dictionary.keys()):\n",
    "                dictionary[y] += 1\n",
    "            else: \n",
    "                dictionary[y] = 1\n",
    "                \n",
    "freq = sorted(dictionary, key=dictionary.get, reverse = True)\n",
    "fredict = {}\n",
    "for x in freq: #organized dictionary by frequency of word in hard skill sample\n",
    "    fredict[x] = dictionary.get(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create list containing data points of raw data, organized in lists containing individual words, with no special characters or numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist_data = []\n",
    "for x in range(0,len(data)):\n",
    "    if len(re.sub(r\"[^a-zA-Z]\",\" \", data.iloc[x,0]).split()) == 0:\n",
    "        wlist_data.append([\"a\"]) #if list is empty, i.e. only had numbers/special characters, place placeholder of \"a\"\n",
    "    else:\n",
    "        wlist_data.append(re.sub(r\"[^a-zA-Z]\",\" \", data.iloc[x,0]).split())\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examined data point in raw data and classified using the following parameters:\n",
    "\n",
    "\n",
    "    - Word appeared in Hard Skill sample\n",
    "    - Word contains more than one capital letter\n",
    "    - Unusual word as per frequency value\n",
    "    - Word not appearing in English dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2 = pd.DataFrame(data = np.zeros(len(data)), columns = ['Result'], dtype = object)\n",
    "reason = []\n",
    "count = 0\n",
    "\n",
    "for x in wlist_data:\n",
    "    \n",
    "    word_position = 0\n",
    "\n",
    "    for y in x: \n",
    "\n",
    "        if y in fredict:\n",
    "            analysis2.iloc[count,0] = 1\n",
    "            reason.append(\"in sample of hard skills\")\n",
    "            count += 1\n",
    "            break\n",
    "        elif y.capitalize() in fredict:\n",
    "            analysis2.iloc[count,0] = 1\n",
    "            reason.append(\"in sample of hard skills\")\n",
    "            count += 1\n",
    "            break\n",
    "        elif sum(1 for c in y if c.isupper()) > 1: #checking for more than one capital letter per word\n",
    "            analysis2.iloc[count,0] = 1\n",
    "            reason.append(\"more than one capital letter\")\n",
    "            count += 1\n",
    "            break  \n",
    "        elif zipf_frequency(y, 'en',wordlist='small') < 3: #frequency of under 3 is considered unusual word\n",
    "            analysis2.iloc[count,0] = 1\n",
    "            reason.append(\"unusual word\")\n",
    "            count += 1\n",
    "            break\n",
    "        elif y.lower() not in worddict[y.lower()[0]]: #searching by initial letter vs. searching whole dictionary reduced run time from 20 minutes to 10 seconds\n",
    "            analysis2.iloc[count,0] = 1\n",
    "            reason.append(\"not in english dictionary\")\n",
    "            count += 1\n",
    "            break\n",
    "        else:\n",
    "            if len(x) > 1 and word_position != len(x)-1: #cycle through all words until reaching last one\n",
    "                word_position += 1 \n",
    "            else: #when last word in list is reached and no classification has been made, classify as not a hard skill\n",
    "                analysis2.iloc[count,0] = 0\n",
    "                reason.append(\"not detected as hard skill\")\n",
    "                count += 1\n",
    "    \n",
    "analysis2.insert(0, \"Data\", list(data.iloc[:,0]))  \n",
    "analysis2.insert(2, \"Reason\", reason)\n",
    "analysis2.to_csv('Hard_Skill_Detection.csv', index = False)\n",
    "analysis2[analysis2.iloc[:,1] == 1][\"Data\"].to_csv('Clean_Data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing results using random sample of 25 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(55)\n",
    "testing = random.sample(list(range(0,len(analysis2)+1)), k = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Result</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>1</td>\n",
       "      <td>more than one capital letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12861</th>\n",
       "      <td>the core banking processor</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9828</th>\n",
       "      <td>iOS/Android automation frameworks</td>\n",
       "      <td>1</td>\n",
       "      <td>more than one capital letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19836</th>\n",
       "      <td>the right tradeoff</td>\n",
       "      <td>1</td>\n",
       "      <td>unusual word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5220</th>\n",
       "      <td>Assess risks</td>\n",
       "      <td>0</td>\n",
       "      <td>not detected as hard skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>announcements</td>\n",
       "      <td>0</td>\n",
       "      <td>not detected as hard skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19787</th>\n",
       "      <td>e.g. PHP</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>a Data Orchestration solutions</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23044</th>\n",
       "      <td>client/developer feedback</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30930</th>\n",
       "      <td>analytical problem-solving skills</td>\n",
       "      <td>0</td>\n",
       "      <td>not detected as hard skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25253</th>\n",
       "      <td>familiarity</td>\n",
       "      <td>0</td>\n",
       "      <td>not detected as hard skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25421</th>\n",
       "      <td>secure coding</td>\n",
       "      <td>0</td>\n",
       "      <td>not detected as hard skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32997</th>\n",
       "      <td>5G</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26590</th>\n",
       "      <td>JavaScript client</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20855</th>\n",
       "      <td>Senior Blockchain Developer</td>\n",
       "      <td>1</td>\n",
       "      <td>not in english dictionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28107</th>\n",
       "      <td>Jenkins</td>\n",
       "      <td>1</td>\n",
       "      <td>not in english dictionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>network troubleshooting experience</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16858</th>\n",
       "      <td>Web Flux/Project Reactor experience</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>Ansible</td>\n",
       "      <td>1</td>\n",
       "      <td>unusual word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15113</th>\n",
       "      <td>SASS</td>\n",
       "      <td>1</td>\n",
       "      <td>more than one capital letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33617</th>\n",
       "      <td>MSAZ</td>\n",
       "      <td>1</td>\n",
       "      <td>more than one capital letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Application Servers</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30442</th>\n",
       "      <td>an RDBMS</td>\n",
       "      <td>1</td>\n",
       "      <td>more than one capital letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14662</th>\n",
       "      <td>Microsoft technology stack</td>\n",
       "      <td>1</td>\n",
       "      <td>in sample of hard skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>microservices architecture</td>\n",
       "      <td>1</td>\n",
       "      <td>unusual word</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Data Result  \\\n",
       "5920                                PySpark      1   \n",
       "12861            the core banking processor      1   \n",
       "9828      iOS/Android automation frameworks      1   \n",
       "19836                    the right tradeoff      1   \n",
       "5220                           Assess risks      0   \n",
       "12043                         announcements      0   \n",
       "19787                              e.g. PHP      1   \n",
       "5800         a Data Orchestration solutions      1   \n",
       "23044             client/developer feedback      1   \n",
       "30930     analytical problem-solving skills      0   \n",
       "25253                           familiarity      0   \n",
       "25421                         secure coding      0   \n",
       "32997                                    5G      1   \n",
       "26590                     JavaScript client      1   \n",
       "20855           Senior Blockchain Developer      1   \n",
       "28107                               Jenkins      1   \n",
       "2658     network troubleshooting experience      1   \n",
       "16858   Web Flux/Project Reactor experience      1   \n",
       "2688                                Ansible      1   \n",
       "15113                                  SASS      1   \n",
       "33617                                  MSAZ      1   \n",
       "953                     Application Servers      1   \n",
       "30442                              an RDBMS      1   \n",
       "14662            Microsoft technology stack      1   \n",
       "3439             microservices architecture      1   \n",
       "\n",
       "                             Reason  \n",
       "5920   more than one capital letter  \n",
       "12861      in sample of hard skills  \n",
       "9828   more than one capital letter  \n",
       "19836                  unusual word  \n",
       "5220     not detected as hard skill  \n",
       "12043    not detected as hard skill  \n",
       "19787      in sample of hard skills  \n",
       "5800       in sample of hard skills  \n",
       "23044      in sample of hard skills  \n",
       "30930    not detected as hard skill  \n",
       "25253    not detected as hard skill  \n",
       "25421    not detected as hard skill  \n",
       "32997      in sample of hard skills  \n",
       "26590      in sample of hard skills  \n",
       "20855     not in english dictionary  \n",
       "28107     not in english dictionary  \n",
       "2658       in sample of hard skills  \n",
       "16858      in sample of hard skills  \n",
       "2688                   unusual word  \n",
       "15113  more than one capital letter  \n",
       "33617  more than one capital letter  \n",
       "953        in sample of hard skills  \n",
       "30442  more than one capital letter  \n",
       "14662      in sample of hard skills  \n",
       "3439                   unusual word  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis2.iloc[testing,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Results appear to indicate a 84% accuracy classification, missing index points 12861,19836,23044, and 25421. \n",
    "\n",
    "\n",
    "Future Considerations:\n",
    "\n",
    "- Data set contained large number of hard skills, would have to try with a data set containing mostly soft skills\n",
    "- Hard skills not extracted from sentences \n",
    "- Frequency of words library contained samples from many sources, including websites. Fiction based library could provide more reliable frequency values for tech words\n",
    "- Further increase hard skill word bank\n",
    "- Use NLTK tools to better analyze the language and adapt to never-before-seen cases\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
